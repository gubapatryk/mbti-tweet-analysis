{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>welcome welcome welcome!! ^^ your type rocks.....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Just realized I completely missed a letter a t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enough to fit a suitcase full of drugs.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thanks! I've been working on opening up a bit ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ok...so im fully aware of my power of persuasi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post type\n",
       "0  welcome welcome welcome!! ^^ your type rocks.....    1\n",
       "1  Just realized I completely missed a letter a t...    1\n",
       "2            Enough to fit a suitcase full of drugs.    1\n",
       "3  Thanks! I've been working on opening up a bit ...    1\n",
       "4  Ok...so im fully aware of my power of persuasi...    1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('mbti_short.csv')\n",
    "df.type = pd.Categorical(pd.factorize(df.type)[0] + 1)\n",
    "df = df[['post', 'type']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with 16 classes ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['post'],\n",
    "                                                    df['type'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english',\n",
    "                             ngram_range=(1,3),\n",
    "                             min_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "723155"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized = vectorizer.fit_transform(X_train.apply(lambda x: np.str_(x)))\n",
    "X_test_vectorized = vectorizer.transform(X_test.apply(lambda x: np.str_(x)))\n",
    "X_train_vectorized\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf1',\n",
       "                 TfidfVectorizer(ngram_range=(1, 3), stop_words='english')),\n",
       "                ('lr', LogisticRegression(C=0.005, class_weight='balanced'))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring = {'acc': 'accuracy',\n",
    "           'f1_micro': 'f1_micro'}\n",
    "\n",
    "#classify(classifier, vectorizer)\n",
    "\n",
    "pipe = Pipeline([('tfidf1', vectorizer), ('lr', LogisticRegression(class_weight=\"balanced\", C=0.005))])\n",
    "\n",
    "pipe.fit(X_train.apply(lambda x: np.str_(x)), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test.apply(lambda x: np.str_(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raport klasyfikacji Logistic: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.21      0.21       341\n",
      "           2       0.22      0.14      0.17       551\n",
      "           3       0.21      0.26      0.23       315\n",
      "           4       0.14      0.16      0.15       291\n",
      "           5       0.29      0.27      0.28       422\n",
      "           6       0.12      0.21      0.16       223\n",
      "           7       0.22      0.20      0.21       420\n",
      "           8       0.14      0.31      0.20       166\n",
      "           9       0.27      0.13      0.18       827\n",
      "          10       0.15      0.15      0.15       396\n",
      "          11       0.23      0.13      0.16       710\n",
      "          12       0.19      0.17      0.18       447\n",
      "          13       0.12      0.26      0.16       172\n",
      "          14       0.15      0.19      0.17       320\n",
      "          15       0.15      0.22      0.18       251\n",
      "          16       0.12      0.19      0.15       251\n",
      "\n",
      "    accuracy                           0.18      6103\n",
      "   macro avg       0.18      0.20      0.18      6103\n",
      "weighted avg       0.20      0.18      0.18      6103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "print(\"Raport klasyfikacji Logistic: \")\n",
    "print(classification_report( y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(eval_metric=\"logloss\")\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "y_pred = clf.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raport klasyfikacji XGB: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.20      0.23      0.21       322\n",
      "           2       0.16      0.17      0.16       328\n",
      "           3       0.17      0.17      0.17       390\n",
      "           4       0.12      0.10      0.11       438\n",
      "           5       0.24      0.26      0.25       376\n",
      "           6       0.21      0.11      0.14       700\n",
      "           7       0.19      0.23      0.21       318\n",
      "           8       0.17      0.17      0.17       358\n",
      "           9       0.14      0.16      0.15       334\n",
      "          10       0.16      0.18      0.17       369\n",
      "          11       0.10      0.13      0.12       315\n",
      "          12       0.16      0.14      0.15       432\n",
      "          13       0.16      0.18      0.17       356\n",
      "          14       0.16      0.17      0.16       379\n",
      "          15       0.17      0.20      0.19       308\n",
      "          16       0.14      0.14      0.14       380\n",
      "\n",
      "    accuracy                           0.17      6103\n",
      "   macro avg       0.17      0.17      0.17      6103\n",
      "weighted avg       0.17      0.17      0.17      6103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "print(\"Raport klasyfikacji XGB: \")\n",
    "print(classification_report( y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer, open(\"vectorizer_xgb_mbti.sav\", 'wb'))\n",
    "pickle.dump(clf, open(\"model_XGB.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result is:  [10]\n",
      "The result is:  [3]\n",
      "The result is:  [4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyse_tweet(tweet):\n",
    "    if type(tweet) != list:\n",
    "        tweet = [tweet]\n",
    "        \n",
    "    loaded_vectorizer = pickle.load(open(\"vectorizer_xgb_mbti.sav\", 'rb'))\n",
    "\n",
    "    loaded_model= pickle.load(open(\"model_XGB.sav\", 'rb'))\n",
    "    input_vect = vectorizer.transform(tweet)\n",
    "\n",
    "    result_type = loaded_model.predict(input_vect)\n",
    "    \n",
    "    print(\"The result is: \", result_type)\n",
    "    \n",
    "    return result_type\n",
    "\n",
    "\n",
    "analyse_tweet(\"Kanye is a typical example of ‚Äòmost‚Äô men always realizing when the person they took for granted moved on! Rooting for KimYe üíØ but Kim Kardashian deserves to be happy as well üìåüòç she loved Ye and fought for that marriage \")\n",
    "analyse_tweet(\"We also passed the Bipartisan Infrastructure Law, which is going to make it easier for businesses to move goods and reach more customers than ever before.My Build Back Better Act will go even further.I‚Äôm looking forward to shopping small tomorrow, and I hope you are too.\")\n",
    "analyse_tweet(\"Mike Pence didn‚Äôt have the courage to do what should have been done to protect our Country and our Constitution, giving States a chance to certify a corrected set of facts, not the fraudulent or inaccurate ones which they were asked to previously certify. USA demands the truth!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Classification 4 x binary instead of 16 classes ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ENFJ' 'ENFP' 'ENTJ' 'ENTP' 'ESFJ' 'ESFP' 'ESTJ' 'ESTP' 'INFJ' 'INFP'\n",
      " 'INTJ' 'INTP' 'ISFJ' 'ISFP' 'ISTJ' 'ISTP']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('mbti_short.csv')\n",
    "df = df[['post', 'type']]\n",
    "\n",
    "\n",
    "print(df['type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english',\n",
    "                             ngram_range=(1,1),\n",
    "                             min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized = vectorizer.fit_transform(train['post'].apply(lambda x: np.str_(x)))\n",
    "X_test_vectorized = vectorizer.transform(test['post'].apply(lambda x: np.str_(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE: Introversion (I) / Extroversion (E)\n",
      "NS: Intuition (N) ‚Äì Sensing (S)\n",
      "FT: Feeling (F) - Thinking (T)\n",
      "JP: Judging (J) ‚Äì Perceiving (P)\n"
     ]
    }
   ],
   "source": [
    "type_indicators = [ \"IE: Introversion (I) / Extroversion (E)\", \"NS: Intuition (N) ‚Äì Sensing (S)\", \n",
    "                   \"FT: Feeling (F) - Thinking (T)\", \"JP: Judging (J) ‚Äì Perceiving (P)\"  ]\n",
    "\n",
    "for l in range(len(type_indicators)):\n",
    "    print(type_indicators[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_Pers = {'I':0, 'E':1, 'N':0, 'S':1, 'F':0, 'T':1, 'J':0, 'P':1}\n",
    "b_Pers_list = [{0:'I', 1:'E'}, {0:'N', 1:'S'}, {0:'F', 1:'T'}, {0:'J', 1:'P'}]\n",
    "\n",
    "def translate_personality(personality):\n",
    "    # transform mbti to binary vector\n",
    "    \n",
    "    return [b_Pers[l] for l in personality]\n",
    "\n",
    "def translate_back(personality):\n",
    "    # transform binary vector to mbti personality\n",
    "    \n",
    "    s = \"\"\n",
    "    for i, l in enumerate(personality):\n",
    "        s += b_Pers_list[i][l]\n",
    "    return s\n",
    "\n",
    "\n",
    "# Posts in tf-idf representation\n",
    "X_train = X_train_vectorized\n",
    "classes_train = np.array([translate_personality(p) for p in train.type])\n",
    "\n",
    "X_test = X_test_vectorized\n",
    "classes_test = np.array([translate_personality(p) for p in test.type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE: Introversion (I) / Extroversion (E) ...\n",
      "[14:34:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " \n",
      " IE: Introversion (I) / Extroversion (E) Accuracy: 58.02 \n",
      "\n",
      "NS: Intuition (N) ‚Äì Sensing (S) ...\n",
      "[14:34:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " \n",
      " NS: Intuition (N) ‚Äì Sensing (S) Accuracy: 61.28 \n",
      "\n",
      "FT: Feeling (F) - Thinking (T) ...\n",
      "[14:34:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " \n",
      " FT: Feeling (F) - Thinking (T) Accuracy: 60.81 \n",
      "\n",
      "JP: Judging (J) ‚Äì Perceiving (P) ...\n",
      "[14:34:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      " \n",
      " JP: Judging (J) ‚Äì Perceiving (P) Accuracy: 56.45 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "result=[]\n",
    "# Let's train type indicator individually\n",
    "for l in range(len(type_indicators)):\n",
    "    print(\"%s ...\" % (type_indicators[l]))\n",
    "    \n",
    "    # Let's train type indicator individually\n",
    "    y_train = classes_train[:,l]\n",
    "    y_test = classes_test[:,l]\n",
    "\n",
    "    # fit model on training data\n",
    "    model =  XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    filename = 'model_' +type_indicators[l][0:2]+'.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "    print(\" \\n %s Accuracy: %.2f \\n\" % (type_indicators[l], accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer, open(\"vectorizer_mbti.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result is:  ENFP\n",
      "The result is:  INFJ\n",
      "The result is:  ISTP\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ISTP'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def analyse_tweet(tweet):\n",
    "    if type(tweet) != list:\n",
    "        tweet = [tweet]\n",
    "        \n",
    "    loaded_vectorizer = pickle.load(open(\"vectorizer_mbti.sav\", 'rb'))\n",
    "\n",
    "    loaded_model_IE = pickle.load(open(\"model_IE.sav\", 'rb'))\n",
    "    loaded_model_NS = pickle.load(open(\"model_NS.sav\", 'rb'))\n",
    "    loaded_model_FT = pickle.load(open(\"model_FT.sav\", 'rb'))\n",
    "    loaded_model_JP = pickle.load(open(\"model_JP.sav\", 'rb'))\n",
    "\n",
    "    input_vect = vectorizer.transform(tweet)\n",
    "    \n",
    "    result_bin = []\n",
    "    result_bin.append(loaded_model_IE.predict(input_vect)[0])\n",
    "    result_bin.append(loaded_model_NS.predict(input_vect)[0])\n",
    "    result_bin.append(loaded_model_FT.predict(input_vect)[0])\n",
    "    result_bin.append(loaded_model_JP.predict(input_vect)[0])\n",
    "\n",
    "    result_type = translate_back(result_bin)\n",
    "    \n",
    "    print(\"The result is: \", result_type)\n",
    "    \n",
    "    return result_type\n",
    "\n",
    "\n",
    "analyse_tweet(\"Kanye is a typical example of ‚Äòmost‚Äô men always realizing when the person they took for granted moved on! Rooting for KimYe üíØ but Kim Kardashian deserves to be happy as well üìåüòç she loved Ye and fought for that marriage \")\n",
    "analyse_tweet(\"We also passed the Bipartisan Infrastructure Law, which is going to make it easier for businesses to move goods and reach more customers than ever before.My Build Back Better Act will go even further.I‚Äôm looking forward to shopping small tomorrow, and I hope you are too.\")\n",
    "analyse_tweet(\"Mike Pence didn‚Äôt have the courage to do what should have been done to protect our Country and our Constitution, giving States a chance to certify a corrected set of facts, not the fraudulent or inaccurate ones which they were asked to previously certify. USA demands the truth!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
